{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from sklearn import svm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visit prediction\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100,000 sets for training and another 100,000 for validation\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "visitVal = []\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if (totalPurchases < 100000):\n",
    "        user,business = l['userID'],l['businessID']\n",
    "        businessCount[business] += 1\n",
    "        totalPurchases += 1\n",
    "    else:\n",
    "        user,business = l['userID'],l['businessID']\n",
    "        visitVal.append((user, business, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100,000 more non-visited data points\n",
    "\n",
    "\n",
    "visited = set()\n",
    "uniqueUser = set()\n",
    "uniqueBuss = set()\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    uniqueUser.add(u)\n",
    "    uniqueBuss.add(b)\n",
    "    visited.add((u,b))\n",
    "\n",
    "for l in range(0,100000):\n",
    "    user = random.sample(uniqueUser, 1)[0]\n",
    "    business = random.sample(uniqueBuss, 1)[0]\n",
    "    while ((user,business) in visited):\n",
    "        user = random.sample(uniqueUser, 1)[0]\n",
    "        business = random.sample(uniqueBuss, 1)[0]\n",
    "    visitVal.append((user,business, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visitVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.623225\n"
     ]
    }
   ],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/2: break\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    if (((b in return1) and (c==1)) or ((b not in return1) and (c==0))) :\n",
    "        correct += 1\n",
    "    index += 1\n",
    "    \n",
    "accuracy = float(correct)/len(visitVal)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58495\n"
     ]
    }
   ],
   "source": [
    "# Try 75th percentile\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/4: break\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    if (((b in return1) and (c==1)) or ((b not in return1) and (c==0))) :\n",
    "        correct += 1\n",
    "    index += 1\n",
    "    \n",
    "accuracy = float(correct)/len(visitVal)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607935\n"
     ]
    }
   ],
   "source": [
    "# Try 25th percentile\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > 3*totalPurchases/4: break\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    if (((b in return1) and (c==1)) or ((b not in return1) and (c==0))) :\n",
    "        correct += 1\n",
    "    index += 1\n",
    "    \n",
    "accuracy = float(correct)/len(visitVal)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62487\n"
     ]
    }
   ],
   "source": [
    "# Try 40th percentile\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > 6*totalPurchases/10: break\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    if (((b in return1) and (c==1)) or ((b not in return1) and (c==0))) :\n",
    "        correct += 1\n",
    "    index += 1\n",
    "    \n",
    "accuracy = float(correct)/len(visitVal)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613105\n"
     ]
    }
   ],
   "source": [
    "# Try 60th percentile\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > 4*totalPurchases/10: break\n",
    "\n",
    "correct = 0\n",
    "index = 0\n",
    "\n",
    "for u,b,c in visitVal:\n",
    "    if (((b in return1) and (c==1)) or ((b not in return1) and (c==0))) :\n",
    "        correct += 1\n",
    "    index += 1\n",
    "    \n",
    "accuracy = float(correct)/len(visitVal)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It seems that 50th percentile gives the highest acuracy and although the 40th percentile test give slightly better in my case, \n",
    "# I believe this is due to random chance. I think it is the best because  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 \n",
    "# Users may tend to repeatedly visit business of the same type. Build a baseline that returns ‘True’ if\n",
    "# a user has visited a business of the same category before (at least one category in common), or zero\n",
    "# otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 100,000 sets for training and another 100,000 for validation\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "visitVal = []\n",
    "userCats = {}\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if (totalPurchases < 100000):\n",
    "        user,business,categories = l['userID'],l['businessID'],l['categories']\n",
    "        userCats[user] = list(set(userCats.get(user,[])).union(categories))\n",
    "        \n",
    "    else:\n",
    "        user,business,categories = l['userID'],l['businessID'],l['categories']\n",
    "        visitVal.append((user, business, categories, 1))\n",
    "            \n",
    "    totalPurchases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Donut Shop',\n",
       " u'European Restaurant',\n",
       " u'Chinese Restaurant',\n",
       " u'Middle Eastern Restaurant',\n",
       " u'Dessert Shop',\n",
       " u'Asian Restaurant',\n",
       " u'Ice Cream Shop']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userCats['U600574911']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create 100,000 more non-visited data points\n",
    "\n",
    "visited = set()\n",
    "uniqueUser = set()\n",
    "uniqueBuss = set()\n",
    "bussCat = {}\n",
    "\n",
    "for u,b,c,d in visitVal:\n",
    "    uniqueUser.add(u)\n",
    "    uniqueBuss.add(b)\n",
    "    visited.add((u,b))\n",
    "    bussCat[b] = c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in range(0,100000):\n",
    "    user = random.sample(uniqueUser, 1)[0]\n",
    "    bussiness = random.sample(uniqueBuss, 1)[0]\n",
    "  \n",
    "    while ((user,business) in visited):\n",
    "        user = random.sample(uniqueUser, 1)[0]\n",
    "        business = random.sample(uniqueBuss, 1)[0]\n",
    "        \n",
    "    visitVal.append((user,business, bussCat[business], 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('U237829706', 'B556394301', [u'Restaurant', u'Soul Food Restaurant'], 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitVal[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('U296072251', 'B589288198', [u'American Restaurant'], 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitVal[100001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62923\n"
     ]
    }
   ],
   "source": [
    "# Test the accuracy\n",
    "\n",
    "predicts = []\n",
    "for user,business,cat,d in visitVal:\n",
    "    cat1 = userCats.get(user,[])\n",
    "\n",
    "    intersection = list(set(cat1) & set(cat))\n",
    "    \n",
    "    if intersection:\n",
    "        predicts.append(1)\n",
    "    else:\n",
    "        predicts.append(0)\n",
    "\n",
    "accuracy = [(a[3]==b) for (a,b) in zip(visitVal,predicts)]\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Visit.txt\", 'w')\n",
    "for l in open(\"pairs_Visit.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "\n",
    "    u,i = l.strip().split('-')\n",
    "    cat1 = userCats.get(u,[])\n",
    "    cat2 = bussCat.get(i,[])\n",
    "    intersection = list(set(cat1) & set(cat2))\n",
    "    \n",
    "    if intersection:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "# I uploaded my solution to Kaggle and got a score of 0.64930\n",
    "# My user name is ddinata on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Category prediction\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasCat = []\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if 'categoryID' in l:\n",
    "        hasCat.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCat = hasCat[:len(hasCat)/2]\n",
    "valCat = hasCat[len(hasCat)/2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35097\n",
      "35098\n",
      "[{'rating': 4.0, 'reviewHash': 'R567271252', 'businessID': 'B423621081', 'unixReviewTime': 1378865039, 'reviewText': u\"I'm a vegetarian, but every so often I want a hotdog with lots of toppings.  And a tall can of beer.  Frank has got that covered.  And they have a cool warehouse space with some pinball machines.  Prices are a little high for hotdogs...fancy hotdogs, but hotdogs nonetheless.  Good location and service, but gets crowded and loud.\", 'userID': 'U985379327', 'reviewTime': u'Sep 10, 2013', 'categories': [u'American Restaurant', u'Cafe', u'Hot Dog Restaurant'], 'categoryID': 0}, {'rating': 4.0, 'reviewHash': 'R985248711', 'businessID': 'B734024511', 'unixReviewTime': 1372977506, 'reviewText': u\"Asia Cafe is hands down the best Chinese food in Austin. Their menu has about 100 different options and it's really authentic. The spicy fish and the garlic pork are two of my favorites. It's a bit far from downtown Austin, right on the outskirts of Round Rock, but it's worth the drive.\", 'userID': 'U272385455', 'reviewTime': u'Jul 4, 2013', 'categories': [u'Chinese Restaurant', u'Asian Restaurant'], 'categoryID': 2}, {'rating': 4.0, 'reviewHash': 'R250266072', 'businessID': 'B276843680', 'unixReviewTime': 1262822400, 'reviewText': u'the name says it all!', 'userID': 'U258716760', 'reviewTime': u'Jan 6, 2010', 'categories': [u'Bar'], 'categoryID': 1}, {'rating': 5.0, 'reviewHash': 'R526444776', 'businessID': 'B929679987', 'unixReviewTime': 1393117550, 'reviewText': u'The deep fried burger is a must try. Definitely the best burger I have had ever. Tasty tasty tasty.', 'userID': 'U794428800', 'reviewTime': u'Feb 22, 2014', 'categories': [u'Eastern European Restaurant', u'European Restaurant', u'Delivery Restaurant'], 'categoryID': 3}, {'rating': 4.0, 'reviewHash': 'R355737687', 'businessID': 'B006984008', 'unixReviewTime': 1355291729, 'reviewText': u'Great happy hour spot.  Stuffed olives with Tequila are really great and unique.', 'userID': 'U827182046', 'reviewTime': u'Dec 11, 2012', 'categories': [u'Mexican Restaurant', u'Latin American Restaurant', u'Nuevo Latino Restaurant'], 'categoryID': 6}]\n"
     ]
    }
   ],
   "source": [
    "print len(trainCat)\n",
    "print len(valCat)\n",
    "print trainCat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"American Restaurant\": 0,\n",
    "  \"Bar\": 1,\n",
    "  \"Asian Restaurant\": 2,\n",
    "  \"European Restaurant\": 3,\n",
    "  \"Italian Restaurant\": 4,\n",
    "  \"Fast Food Restaurant\": 5,\n",
    "  \"Mexican Restaurant\": 6,\n",
    "  \"Seafood Restaurant\": 7,\n",
    "  \"Coffee Shop\": 8,\n",
    "  \"Sandwich Shop\": 9\n",
    "}\n",
    "\n",
    "userCats = {}\n",
    "for l in trainCat:\n",
    "    user,business,categoryID = l['userID'],l['businessID'],l['categoryID']\n",
    "    if user not in userCats:\n",
    "        userCats[user] = {}\n",
    "    if categoryID not in userCats[user]:\n",
    "        userCats[user][categoryID] = 0\n",
    "    userCats[user][categoryID] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userCats[random.sample(userCats, 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(userCats['U156843408'], key=userCats['U156843408'].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.292039432446\n"
     ]
    }
   ],
   "source": [
    "predicts = []\n",
    "for l in valCat:\n",
    "    if l['userID'] not in userCats:\n",
    "        predicts.append(0)\n",
    "        continue\n",
    "    prediction = max(userCats[l['userID']], key=userCats[l['userID']].get)\n",
    "    predicts.append(prediction)\n",
    "\n",
    "accuracy = [(a['categoryID']==b) for (a,b) in zip(valCat,predicts)]\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26833\n"
     ]
    }
   ],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "for l in trainCat:\n",
    "    for w in l['reviewText'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "        w = stemmer.stem(w)\n",
    "        wordCount[w] += 1\n",
    "print len(wordCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107503\n"
     ]
    }
   ],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "# words contain the 500 most popular words in the entire trainCat\n",
    "words = [x[1] for x in counts [:500]]\n",
    "\n",
    "sum500 = sum(wordCount[w] for w in words)\n",
    "print sum500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "\n",
    "for w in words:\n",
    "    frequency[w] = 1.0*wordCount[w]/sum500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sets for each category from the train set\n",
    "\n",
    "americanTrain = []\n",
    "barTrain = []\n",
    "asianTrain = []\n",
    "europeanTrain = []\n",
    "italianTrain = []\n",
    "fastTrain = []\n",
    "mexicanTrain = []\n",
    "seafoodTrain = []\n",
    "coffeeTrain = []\n",
    "sandwichTrain = []\n",
    "\n",
    "americanfreq = {}\n",
    "barfreq = {}\n",
    "asianfreq = {}\n",
    "europeanfreq = {}\n",
    "italianfreq = {}\n",
    "fastfreq = {}\n",
    "mexicanfreq = {}\n",
    "seafoodfreq = {}\n",
    "coffeefreq = {}\n",
    "sandwichfreq = {}\n",
    "\n",
    "for l in trainCat:\n",
    "    if l['categoryID'] == 0:\n",
    "        americanTrain.append(l)\n",
    "    if l['categoryID'] == 1:\n",
    "        barTrain.append(l)\n",
    "    if l['categoryID'] == 2:\n",
    "        asianTrain.append(l)\n",
    "    if l['categoryID'] == 3:\n",
    "        europeanTrain.append(l)\n",
    "    if l['categoryID'] == 4:\n",
    "        italianTrain.append(l)\n",
    "    if l['categoryID'] == 5:\n",
    "        fastTrain.append(l)\n",
    "    if l['categoryID'] == 6:\n",
    "        mexicanTrain.append(l)\n",
    "    if l['categoryID'] == 7:\n",
    "        seafoodTrain.append(l)\n",
    "    if l['categoryID'] == 8:\n",
    "        coffeeTrain.append(l)\n",
    "    if l['categoryID'] == 9:\n",
    "        sandwichTrain.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freqCat(_train, _freq):\n",
    "    _wordCount = defaultdict(int)\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    for l in _train:\n",
    "        for w in l['reviewText'].split():\n",
    "            w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "            w = stemmer.stem(w)\n",
    "            _wordCount[w] += 1\n",
    "\n",
    "    _sum500 = sum(_wordCount[w] for w in words)\n",
    "    print _sum500\n",
    "\n",
    "    for w in words:\n",
    "        _freq[w] = 1.0*_wordCount[w]/_sum500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339375\n"
     ]
    }
   ],
   "source": [
    "freqCat(americanTrain, americanfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144194\n"
     ]
    }
   ],
   "source": [
    "freqCat(barTrain, barfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234667\n"
     ]
    }
   ],
   "source": [
    "freqCat(asianTrain, asianfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53876\n"
     ]
    }
   ],
   "source": [
    "freqCat(europeanTrain, europeanfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32612\n"
     ]
    }
   ],
   "source": [
    "freqCat(italianTrain, italianfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500\n"
     ]
    }
   ],
   "source": [
    "freqCat(fastTrain, fastfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107397\n"
     ]
    }
   ],
   "source": [
    "freqCat(mexicanTrain, mexicanfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60175\n"
     ]
    }
   ],
   "source": [
    "freqCat(seafoodTrain, seafoodfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74090\n"
     ]
    }
   ],
   "source": [
    "freqCat(coffeeTrain, coffeefreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29617\n"
     ]
    }
   ],
   "source": [
    "freqCat(sandwichTrain, sandwichfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffamericanfreq = {}\n",
    "diffbarfreq = {}\n",
    "diffasianfreq = {}\n",
    "diffeuropeanfreq = {}\n",
    "diffitalianfreq = {}\n",
    "difffastfreq = {}\n",
    "diffmexicanfreq = {}\n",
    "diffseafoodfreq = {}\n",
    "diffcoffeefreq = {}\n",
    "diffsandwichfreq = {}\n",
    "\n",
    "for w in words:     \n",
    "    diffamericanfreq[w] = americanfreq[w] - frequency[w]\n",
    "    diffbarfreq[w] = barfreq[w] - frequency[w]\n",
    "    diffasianfreq[w] = asianfreq[w] - frequency[w]\n",
    "    diffeuropeanfreq[w] = europeanfreq[w]- frequency[w]\n",
    "    diffitalianfreq[w] = italianfreq[w]- frequency[w]\n",
    "    difffastfreq[w] = fastfreq[w]- frequency[w]\n",
    "    diffmexicanfreq[w] = mexicanfreq[w]- frequency[w]\n",
    "    diffseafoodfreq[w] = seafoodfreq[w]- frequency[w]\n",
    "    diffcoffeefreq[w] = coffeefreq[w]- frequency[w]\n",
    "    diffsandwichfreq[w] = sandwichfreq[w]- frequency[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List the 10 words that appear more frequently in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'wa', u'the', u'brunch', u'food', u'breakfast', u'burger', u'menu', u'had', u'we', u'servic']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentAmerican = sorted(diffamericanfreq, key=diffamericanfreq.get, reverse=True)[:10]\n",
    "print moreFrequentAmerican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'a', u'bar', u'drink', u'beer', u'to', u'night', u'music', u'place', u'great', u'of']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentBar = sorted(diffbarfreq, key=diffbarfreq.get, reverse=True)[:10]\n",
    "print moreFrequentBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'sushi', u'thai', u'food', u'noodl', u'dish', u'chines', u'restaur', u'roll', u'indian', u'ramen']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentAsian = sorted(diffasianfreq, key=diffasianfreq.get, reverse=True)[:10]\n",
    "print moreFrequentAsian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'pizza', u'beer', u'and', u'wa', u'great', u'the', u'with', u'a', u'wine', u'chees']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentEuropean = sorted(diffeuropeanfreq, key=diffeuropeanfreq.get, reverse=True)[:10]\n",
    "print moreFrequentEuropean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'pizza', u'wine', u'restaur', u'the', u'veri', u'bread', u'wa', u'and', u'reserv', u'great']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentItalian = sorted(diffitalianfreq, key=diffitalianfreq.get, reverse=True)[:10]\n",
    "print moreFrequentItalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'burger', u'fri', u'are', u'fast', u'you', u'they', u'their', u'sandwich', u'order', u'line']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentFast = sorted(difffastfreq, key=difffastfreq.get, reverse=True)[:10]\n",
    "print moreFrequentFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'taco', u'mexican', u'food', u'burrito', u'margarita', u'salsa', u'are', u'chip', u'i', u'the']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentMexican = sorted(diffmexicanfreq, key=diffmexicanfreq.get, reverse=True)[:10]\n",
    "print moreFrequentMexican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'seafood', u'fish', u'wa', u'the', u'we', u'crab', u'fresh', u'view', u'steak', u'roll']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentSeafood = sorted(diffseafoodfreq, key=diffseafoodfreq.get, reverse=True)[:10]\n",
    "print moreFrequentSeafood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'coffe', u'shop', u'to', u'i', u'a', u'tea', u'they', u'cafe', u'place', u'their']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentCoffee = sorted(diffcoffeefreq, key=diffcoffeefreq.get, reverse=True)[:10]\n",
    "print moreFrequentCoffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'sandwich', u'chees', u'bread', u'their', u'they', u'i', u'are', u'lunch', u'soup', '']\n"
     ]
    }
   ],
   "source": [
    "moreFrequentSandwich = sorted(diffsandwichfreq, key=diffsandwichfreq.get, reverse=True)[:10]\n",
    "print moreFrequentSandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7\n",
    "#Train an SVM to distinguish Bars and non-Bars only. That is, discard all other categories from the\n",
    "#training set in order to train a binary classifier, but keep them in the validation set (your classifier will\n",
    "#simply be wrong for those instances). Train for C ∈ {0.01, 0.1, 1, 10, 100} (the regularization parameter\n",
    "#for the SVM) and report the best performance you obtain on the validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a mapping of word to index\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "index = 0\n",
    "\n",
    "for w in words:\n",
    "    word_to_index[w] = index\n",
    "    index_to_word[index] = w\n",
    "    index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a feature vector out of the 500 most common words and train to categorize bar\n",
    "\n",
    "barX_train = []\n",
    "barY_train = []\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "for l in trainCat[:3500]:\n",
    "    \n",
    "    featureVector = [0] * 500\n",
    "    for w in l['reviewText'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "        w = stemmer.stem(w)\n",
    "        if (w in words):\n",
    "            featureVector[word_to_index[w]] += 1\n",
    "    \n",
    "    barX_train.append(featureVector)\n",
    "    if l['categoryID'] == 1:\n",
    "        barY_train.append(1)\n",
    "    else:\n",
    "        barY_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "barX_val = []\n",
    "\n",
    "for l in valCat[:3500]:\n",
    "\n",
    "    featureVector = [0] * 500\n",
    "    for w in l['reviewText'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "        w = stemmer.stem(w)\n",
    "        if (w in words):\n",
    "            featureVector[word_to_index[w]] += 1\n",
    "    \n",
    "    barX_val.append(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877032810271\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.01, kernel='linear')\n",
    "clf.fit(barX_train, barY_train)\n",
    "\n",
    "\n",
    "val_predictions = clf.predict(barX_val)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for (a,b) in zip(valCat[:3500], val_predictions):\n",
    "    if a['categoryID'] == 1 and b==1:\n",
    "        accuracy.append(1)\n",
    "    if a['categoryID'] != 1 and b==0:\n",
    "        accuracy.append(1)\n",
    "    else: \n",
    "        accuracy.append(0)\n",
    "\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864383180173\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.1, kernel='linear')\n",
    "clf.fit(barX_train, barY_train)\n",
    "\n",
    "\n",
    "val_predictions = clf.predict(barX_val)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for (a,b) in zip(valCat[:3500], val_predictions):\n",
    "    if a['categoryID'] == 1 and b==1:\n",
    "        accuracy.append(1)\n",
    "    if a['categoryID'] != 1 and b==0:\n",
    "        accuracy.append(1)\n",
    "    else: \n",
    "        accuracy.append(0)\n",
    "\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848725678268\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=1, kernel='linear')\n",
    "clf.fit(barX_train, barY_train)\n",
    "\n",
    "\n",
    "val_predictions = clf.predict(barX_val)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for (a,b) in zip(valCat[:3500], val_predictions):\n",
    "    if a['categoryID'] == 1 and b==1:\n",
    "        accuracy.append(1)\n",
    "    if a['categoryID'] != 1 and b==0:\n",
    "        accuracy.append(1)\n",
    "    else: \n",
    "        accuracy.append(0)\n",
    "\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825635419514\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, kernel='linear')\n",
    "clf.fit(barX_train, barY_train)\n",
    "\n",
    "\n",
    "val_predictions = clf.predict(barX_val)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for (a,b) in zip(valCat[:3500], val_predictions):\n",
    "    if a['categoryID'] == 1 and b==1:\n",
    "        accuracy.append(1)\n",
    "    if a['categoryID'] != 1 and b==0:\n",
    "        accuracy.append(1)\n",
    "    else: \n",
    "        accuracy.append(0)\n",
    "\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822519083969\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=100, kernel='linear')\n",
    "clf.fit(barX_train, barY_train)\n",
    "\n",
    "\n",
    "val_predictions = clf.predict(barX_val)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for (a,b) in zip(valCat[:3500], val_predictions):\n",
    "    if a['categoryID'] == 1 and b==1:\n",
    "        accuracy.append(1)\n",
    "    if a['categoryID'] != 1 and b==0:\n",
    "        accuracy.append(1)\n",
    "    else: \n",
    "        accuracy.append(0)\n",
    "\n",
    "print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C = 0.01 seems to be give the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_prep(id):\n",
    "    barX_train = []\n",
    "    barY_train = []\n",
    "\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    for l in trainCat[:3500]:\n",
    "\n",
    "        featureVector = [0] * 500\n",
    "        for w in l['reviewText'].split():\n",
    "            w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "            w = stemmer.stem(w)\n",
    "            if (w in words):\n",
    "                featureVector[word_to_index[w]] += 1\n",
    "\n",
    "        barX_train.append(featureVector)\n",
    "        if l['categoryID'] == id:\n",
    "            barY_train.append(1)\n",
    "        else:\n",
    "            barY_train.append(0)\n",
    "    barX_val = []\n",
    "\n",
    "    for l in valCat[:3500]:\n",
    "\n",
    "        featureVector = [0] * 500\n",
    "        for w in l['reviewText'].split():\n",
    "            w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "            w = stemmer.stem(w)\n",
    "            if (w in words):\n",
    "                featureVector[word_to_index[w]] += 1\n",
    "\n",
    "        barX_val.append(featureVector)\n",
    "    \n",
    "    return (barX_train, barY_train, barX_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_decision(x_train, y_train, x_val, _c):\n",
    "\n",
    "    clf = svm.SVC(C=_c, kernel='linear')\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    val_predictions = clf.predict(x_val)\n",
    "    decision = clf.decision_function(x_val)\n",
    "    return decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "cat_prep = []\n",
    "\n",
    "for c in range(10):\n",
    "    cat_prep.append(train_val_prep(c))\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "cat_2d = []\n",
    "cVals = [0.01, 0.1, 1, 10, 100]\n",
    "counter = 0\n",
    "\n",
    "for c in cVals:\n",
    "    cat_predicts = []\n",
    "    for l in range(10):\n",
    "        cat_predicts.append(svm_decision(cat_prep[l][0], cat_prep[l][1], cat_prep[l][2],c))\n",
    "        counter += 1\n",
    "        print counter\n",
    "    cat_2d.append(cat_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for c in cat_2d:\n",
    "    preds = []\n",
    "    for i in range(3500):\n",
    "        value = -10000\n",
    "        index = -1\n",
    "        for j in range(10):\n",
    "            if c[j][i] > value:\n",
    "                value = c[j][i]\n",
    "                index = j\n",
    "        preds.append(index)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_get(item):\n",
    "    accuracy = []\n",
    "    \n",
    "    Y_val= []\n",
    "    for c in valCat[:3500]:\n",
    "        Y_val.append(c['categoryID'])\n",
    "    \n",
    "    for (a,b) in zip(Y_val, item):\n",
    "        if a==b:\n",
    "            accuracy.append(1)\n",
    "        else:\n",
    "            accuracy.append(0)\n",
    "\n",
    "    print 1.0*sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511142857143\n",
      "0.498\n",
      "0.462857142857\n",
      "0.423428571429\n",
      "0.384571428571\n"
     ]
    }
   ],
   "source": [
    "for c in predictions:\n",
    "    accuracy_get(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The highest c value is  0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create predictions for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features = [] \n",
    "valid_labels = []\n",
    "\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "        featureVector = [0] * 500\n",
    "        for w in l['reviewText'].split():\n",
    "            w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "            w = stemmer.stem(w)\n",
    "            if (w in words):\n",
    "                featureVector[word_to_index[w]] += 1\n",
    "\n",
    "        valid_features.append(featureVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_prep2 = []\n",
    "for i in range(10): \n",
    "    barX_train = []\n",
    "    barY_train = []\n",
    "\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    for l in trainCat[:3500]:\n",
    "\n",
    "        featureVector = [0] * 500\n",
    "        for w in l['reviewText'].split():\n",
    "            w = ''.join([c for c in w.lower() if not c in punctuation])\n",
    "            w = stemmer.stem(w)\n",
    "            if (w in words):\n",
    "                featureVector[word_to_index[w]] += 1\n",
    "\n",
    "        barX_train.append(featureVector)\n",
    "        if l['categoryID'] == i:\n",
    "            barY_train.append(1)\n",
    "        else:\n",
    "            barY_train.append(0)\n",
    "    cat_prep2.append((barX_train,barY_train,valid_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "cat_3d = []\n",
    "cat_predicts = []\n",
    "c = 0.01\n",
    "for l in range(10):\n",
    "    cat_predicts.append(svm_decision(cat_prep2[l][0], cat_prep2[l][1], cat_prep2[l][2],c))\n",
    "    counter += 1\n",
    "    print counter\n",
    "cat_3d.append(cat_predicts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for c in cat_3d:\n",
    "    preds = []\n",
    "    for i in range(20000):\n",
    "        value = -10000\n",
    "        index = -1\n",
    "        for j in range(10):\n",
    "            if c[j][i] > value:\n",
    "                value = c[j][i]\n",
    "                index = j\n",
    "            preds.append(index)\n",
    "        pred_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
